{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Time_series_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincentsun870530/Soen490/blob/iteration6_li/Time_series_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Pmxv2ioyCRw"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors. \n",
        "##### Ref: https://www.tensorflow.org/tutorials/structured_data/time_series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRdYIQcfyhBY",
        "colab_type": "text"
      },
      "source": [
        "# Install nvidia tool to test GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFjBNb7UxuBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nvidia-ml-py3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YywfC00_2W1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# Time series forecasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7rZnJaGTWQw0",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import nvidia_smi\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TokBlnUhWFw9"
      },
      "source": [
        "## The traffic intersection dataset\n",
        "This uses a Moscow time series dataset(https://www.youtube.com/watch?v=yXXrz1vITNM) recorded by the ???.\n",
        "\n",
        "This dataset contains "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TX6uGeeeWIkG",
        "colab": {}
      },
      "source": [
        "#df = pd.read_csv(csv_path)\n",
        "df = pd.read_csv(io.StringIO(uploaded['generatedDataset.csv'].decode('utf-8')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VdbOWXiTWM2T"
      },
      "source": [
        "Let's take a glance at the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ojHE-iCCWIhz",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qfbpcV0MWQzl"
      },
      "source": [
        "As you can see above,\n",
        "\n",
        "The function below returns the above described windows of time for the model to train on. The parameter `history_size` is the size of the past window of information. The `target_size` is how far in the future does the model need to learn to predict. The `target_size` is the label that needs to be predicted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7AoxQuTrWIbi",
        "colab": {}
      },
      "source": [
        "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i)\n",
        "    # Reshape data from (history_size,) to (history_size, 1)\n",
        "    data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
        "    labels.append(dataset[i+target_size])\n",
        "  return np.array(data), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qoFJZmXBaxCc"
      },
      "source": [
        "The first 8,000 rows of the data will be the training dataset, and there remaining will be the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ia-MPAHxbInX",
        "colab": {}
      },
      "source": [
        "TRAIN_SPLIT = 8000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EowWDtaNnH1y"
      },
      "source": [
        "Setting seed to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-x-GgENynHdx",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8YEwr-NoWUpV"
      },
      "source": [
        "First, we will train a model using only a single feature (6:00-7:00am), and use it to make predictions for that value in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nbdcnm1_WIY9",
        "colab": {}
      },
      "source": [
        "uni_data = df['6:00-7:00am']\n",
        "uni_data.index = df['id']\n",
        "uni_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aQB-46MyWZMm"
      },
      "source": [
        "Let's observe how this data looks across time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ftOExwAqWXSU",
        "colab": {}
      },
      "source": [
        "uni_data.plot(subplots=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ejSEiDqBWXQa",
        "colab": {}
      },
      "source": [
        "uni_data = uni_data.values\n",
        "uni_data.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-eFckdUUHWmT"
      },
      "source": [
        "It is important to scale features before training a neural network. Standardization is a common way of doing this scaling by subtracting the mean and dividing by the standard deviation of each feature.You could also use a `tf.keras.utils.normalize` method that rescales the values into a range of [0,1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mxbIic5TMlxx"
      },
      "source": [
        "Note: The mean and standard deviation should only be computed using the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Eji6njXvHusN",
        "colab": {}
      },
      "source": [
        "uni_train_mean = uni_data[:TRAIN_SPLIT].mean()\n",
        "uni_train_std = uni_data[:TRAIN_SPLIT].std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Gob1YJYH0cH"
      },
      "source": [
        "Let's standardize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BO55yRD6H0Dx",
        "colab": {}
      },
      "source": [
        "uni_data = (uni_data-uni_train_mean)/uni_train_std\n",
        "uni_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gn8A_nrccKtn"
      },
      "source": [
        "Let's now create the data for the univariate model. For part 1, the model will be given the last 20 recorded temperature observations, and needs to learn to predict the temperature at the next time step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJJ-T49vWXOZ",
        "colab": {}
      },
      "source": [
        "univariate_past_history = 60\n",
        "univariate_future_target = 0\n",
        "\n",
        "x_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT,\n",
        "                                           univariate_past_history,\n",
        "                                           univariate_future_target)\n",
        "x_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, None,\n",
        "                                       univariate_past_history,\n",
        "                                       univariate_future_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx4IPHYR0jjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val_uni[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tcQlknf0iPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val_uni[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6_w5Pd70eU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_uni\n",
        "#x_train_uni.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS9bWU0c0gZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_uni\n",
        "#y_train_uni.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aWpVMENsdp0N"
      },
      "source": [
        "This is what the `univariate_data` function returns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "feDd95XFdz5H",
        "colab": {}
      },
      "source": [
        "print ('Single window of past history')\n",
        "print (x_train_uni[4])\n",
        "print ('\\n Target temperature to predict')\n",
        "print (y_train_uni[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hni3Jt9OMR1_"
      },
      "source": [
        "Now that the data has been created, let's take a look at a single example. The information given to the network is given in blue, and it must predict the value at the red cross."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qVukM9dRipop",
        "colab": {}
      },
      "source": [
        "def create_time_steps(length):\n",
        "  time_steps = []\n",
        "  for i in range(-length, 0, 1):\n",
        "    time_steps.append(i)\n",
        "  return time_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QQeGvh7cWXMR",
        "colab": {}
      },
      "source": [
        "def show_plot(plot_data, delta, title):\n",
        "  labels = ['History', 'True Future', 'Model Prediction']\n",
        "  marker = ['.-', 'rx', 'go']\n",
        "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
        "  if delta:\n",
        "    future = delta\n",
        "  else:\n",
        "    future = 0\n",
        "\n",
        "  plt.title(title)\n",
        "  for i, x in enumerate(plot_data):\n",
        "    if i:\n",
        "      plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "               label=labels[i])\n",
        "    else:\n",
        "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "  plt.legend()\n",
        "  plt.xlim([time_steps[0], (future+5)*2])\n",
        "  plt.xlabel('Time-Step')\n",
        "  return plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pd05iV-UWXKL",
        "colab": {}
      },
      "source": [
        "show_plot([x_train_uni[2], y_train_uni[2]], 0, 'Sample Example')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b5rUJ_2YMWzG"
      },
      "source": [
        "### Baseline\n",
        "Before proceeding to train a model, let's first set a simple baseline. Given an input point, the baseline method looks at all the history and predicts the next point to be the average of the last 60 observations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P9nYWcxMMWnr",
        "colab": {}
      },
      "source": [
        "def baseline(history):\n",
        "  return np.mean(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KMcdFYKQMWlm",
        "colab": {}
      },
      "source": [
        "show_plot([x_train_uni[2], y_train_uni[2], baseline(x_train_uni[2])], 0,\n",
        "           'Baseline Prediction Example')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "067m6t8cMakb"
      },
      "source": [
        "Let's see if you can beat this baseline using a recurrent neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "### Recurrent neural network\n",
        "\n",
        "A Recurrent Neural Network (RNN) is a type of neural network well-suited to time series data. RNNs process a time series step-by-step, maintaining an internal state summarizing the information they've seen so far. For more details, read the [RNN tutorial](https://www.tensorflow.org/tutorials/sequences/recurrent). In this tutorial, you will use a specialized RNN layer called Long Short Term Memory ([LSTM](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM))\n",
        "\n",
        "Let's now use `tf.data` to shuffle, batch, and cache the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kk-evkrmMWh9",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
        "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
        "val_univariate = val_univariate.batch(BATCH_SIZE).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n2AmKkyVS5Ht"
      },
      "source": [
        "The following visualisation should help you understand how the data is represented after batching.\n",
        "\n",
        "![Time Series](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/time_series.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4nagdTRNfPuZ"
      },
      "source": [
        "You will see the LSTM requires the input shape of the data it is being given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IDbpHosCMWZO",
        "colab": {}
      },
      "source": [
        "simple_lstm_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(8, input_shape=x_train_uni.shape[-2:]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "simple_lstm_model.compile(optimizer='adam', loss='mae')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NOGZtDAqMtSi"
      },
      "source": [
        "Let's make a sample prediction, to check the output of the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2mPZbIKCMtLR",
        "colab": {}
      },
      "source": [
        "for x, y in val_univariate.take(1):\n",
        "    print(simple_lstm_model.predict(x).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QYz6RN_mMyau"
      },
      "source": [
        "Let's train the model now. Due to the large size of the dataset, in the interest of saving time, each epoch will only run for 200 steps, instead of the complete training data as normally done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0opH9xi5MtIk",
        "colab": {}
      },
      "source": [
        "EVALUATION_INTERVAL = 8000\n",
        "EPOCHS = 100\n",
        "\n",
        "simple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n",
        "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                      validation_data=val_univariate, validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "euyPo_lyNryZ"
      },
      "source": [
        "#### Predict using the simple LSTM model\n",
        "Now that you have trained your simple LSTM, let's try and make a few predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S2rRLrs8MtGU",
        "colab": {}
      },
      "source": [
        "for x, y in val_univariate.take(3):\n",
        "  plot = show_plot([x[0].numpy(), y[0].numpy(),\n",
        "                    simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n",
        "  plot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q-AVEJyRNvt0"
      },
      "source": [
        "This looks better than the baseline. Now that you have seen the basics, let's move on to part two, where you will work with a multivariate time series."
      ]
    }
  ]
}